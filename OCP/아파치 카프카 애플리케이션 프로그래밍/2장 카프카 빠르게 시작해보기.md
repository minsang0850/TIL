## 실습용 카프카 브로커 설치
AWS 사용.

### AWS EC2 인스턴스 발급 및 보안 설정
AWS에서 카프카를 구축할 수 있는 방법은 크게 두 가지가 있다.
첫 번째는 MSK(Managed Service Kafka)를 사용하는 것이고,
두 번째는 EC2(Elastic Compute Cloud)에서 인스턴스를 발급받아서 설치 및 실행하는 방식이다.

MSK는 AWS에서 공식적으로 지원하는 완전 관리형 카프카 서비스로 간단한 콘솔 세팅을 통해 AWS에서 카프카 설치와 실행을 자동화하여 도와준다.

보안 그룹은 크게 Inbound, Outbound 설정으로 나뉘며 프로토콜, 포트, 실행 IP 등에 대해 규칙을 정할 수 있다.
Inbound란 발급받은 인스턴스 외부로부터 들어오는 트래픽을 뜻하고 Outbound란 인스턴스로 나가는 트래픽을 뜻한다.
보안 그룹은 Inbound는 ssh(22번 포트)만 가능, Outbound는 모든 IP, 모든 port 접속 가능으로 기본 설정되어 있다.

카프카 브로커의 기본 포트는 9092이고 주키퍼의 기본 포트는 2181이다.
EC2에 설치된 브로커에 접속하기 위해서는 AWS EC2의 보안 그룹(security group)의 Inbound 설정에 9092와 2181 포트를 열어야 한다. 
source IP는 자신의 IP를 사용하면 실습을 하는 컴퓨터에서만 접속이 가능하다.

실제 운영환경에서는 카프카 접속이 필요한 IP와 포트를 지정하는 것이 카프카를 가장 안전하게 운영하는 방법이다.

### 인스턴스에 접속하기
**ssh 명령어로 접속하기**  
ssh는 네트워크 상의 다른 컴퓨터에 접속할 때 사용하는 명령어이다.
발급한 EC2 인스턴스에 접속하기 위해서는 -i 옵션을 사용하여 key 파일을 프라이빗 키로 추가해야 한다.
-i는 비밀 키를 읽어올 파일의 경로를 추가하는 옵션이다.
인스턴스에 접속하기 위해서는 key 파일이 read 권한만 가지고 있어야 하므로 권한 변경 명령어인 chmod를 사용하여 400으로 설정한다.
<pre><code>chmod 400 test-kafka-server-key.pem
ll test-kafka-server-key.pem
</code></pre>

<pre><code>ssh -i test-kafka-server-key.pem ec2-user@privateIP
</code></pre>

### 인스턴스에 자바 설치
카프카 브로커를 실행하기 위해서 JDK가 필요하다.
카프카 브로커는 스칼라와 자바로 작성되어 JVM 환경 위에서 실행되기 때문이다.
<pre><code>sudo yum install -y java-1.8.0-openjdk-devel.x86_64
java -version
</code></pre>

### 주키퍼∙카프카 브로커 실행
카프카 브로커를 실행하기 위해서 카프카 바이너리 패키지를 다운로드한다.
카프카 바이너리 패키지에는 자바 소스코드를 컴파일하여 실행하기 위해 준비해 놓은 바이너리 파일들이 들어 있다.

<pre><code>wget https://archive.apache.org/dist/kafka/2.5.0/kafka_2.12-2.5.0.tgz
tar xvf kafka_2.12-2.5.0.tgz
</code></pre>

**카프카 브로커 힙 메모리 설정**  
카프카 브로커를 실행하기 위해서는 힙 메모리 설정이 필요하다.
카프카 브로커는 레코드의 내용은 페이지 캐시로 시스템 메모리를 사용하고 나머지 객체들을 힙 메모리에 저장하여 사용한다는 특징이 있다.

<pre><code>export KAFKA_HEAP_OPTS="-Xmx400m -Xms400m"
echo $KAFKA_HEAP_OPTS
</code></pre>

터미널에서 사용자가 입력한 KAFKA_HEAP_OPTS 환경변순느 터미널 세션이 종료되고 나면 다시 초기화되어 재사용이 불가하다.
이를 해결하기 위해 KAFKA_HEAP_OPTS 환경변수 선언문을 ~/.bashrc 파일에 넣으면 된다.  
실습중인 Amazon Linux 2 AMIL 인스턴스에서는 bash 쉘이라고 불리는 유닉스 쉘을 사용하는데,
~/.bashrc 파일은 bash 쉘이 실행될 때마다 반복적으로 구동되어 적용되는 파일이다.  

**바로 적용**
<pre><code>source ~/.bashrc</code></pre>

**카프카 브로커 실행 옵션 설정**  
<pre><code>vi config/server.properties</code></pre>
각종 설정 가능

**주키퍼 실행**  
카프카 바이너리가 포함도니 폴더에는 브로커와 같이 실행할 주키퍼가 준비되어 있다.
분산 코디네이션 서비스를 제공하는 주키퍼는 카프카의 클러스터 설정 리더 정보, 컨트롤러 정보를 담고 있어 카프카를 실행하는 데에 필요한 필수 애플리케이션이다.

1대만 실행하는 주키퍼를 'Quick-and-dirty-single-node'라고 부른다. 
즉, 주키퍼를 1대만 실행하여 사용하는 것은 비정상적인 운영임을 뜻하므로 실제 서비스 운영환경에서는 1대만 사용하면 안 되고, 테스트 목적으로만 사용해야 한다.
주키퍼가 정상적으로 실행되었는지 jps 명령어로 확인할 수 있다.

jps는 JVM 프로세스 상태를 보는 도구로서 JVM 위에서 동작하는 주키퍼의 프로세스를 확인할 수 있다.
-m 옵션과 함께 사용하면 main 메서드에 전달된 인자를 확인할 수 있고, -v 옵션을 사용하면 JVM에 전달된 인자(힙 메모리 설정, log4j 설정 등)를 함께 확인할 수 있다.
<pre><code>bin/zookeeper-server-start.sh -daemon config/zookeeper.properties
jps -vm
</code></pre>

**카프카 브로커 실행 및 로그 확인**  
<pre><code>bin/kafka-server-start.sh -daemon config/server.properties
jps -vm
tail -f logs/server.log
</code></pre>
카프카 클러스터를 운영할 때 이슈가 발생할 경우 모두 카프카 브로커에 로그가 남는다.

### 로컬 컴퓨터에서 카프카와 통신 확인
카프카가 정상 동작하는지 확인하는 가장 쉬운 방법은 카프카 브로커 정보를 요청하는 것이다.
카프카 바이너리 패키지는 카프카 브로커에 대한 정보를 가져올 수 있는 kafka-broker-api-versions.sh 명령어를 제공한다.

**로컬**
<pre><code>curl https://archive.apache.org/dist/kafka/2.5.0/kafka_2.12-2.5.0.tgz --output kafka.tgz
tar -xvf kafka.tgz
cd kafka_2.12-2.5.0
bin/kafka-broker-api-versions.sh --bootstrap-server 13bin/kafka-broker-api-versions.sh --bootstrap-server privateIP:9092
</code></pre>

**테스트 편의를 위한 hosts 설정**  
필요하면 hostFile 수정

## 카프카 커맨드 라인 툴
카프카에서 제공하는 카프카 커맨드 라인 툴들은 카프카를 운영할 때 가장 많이 접하는 도구다.
커맨드 라인 툴을 통해 카프카 브로커 운영에 필요한 다양한 명령을 내릴 수 있다.
카프카 클라이언트 애플리케이션을 운영할 때는 카프카 클러스터와 연동하여 데이터를 주고받는 것도 중요하지만 
토픽이나 파티션 개수 변경과 같은 명령을 실행해야 하는 경우도 자주 발생한다.

카프카 브로커가 설치된 인스턴스에 ssh로 원격 접속하여 명령을 실행해도 되고, 브로커에 9092(카프카 기본 설정 포트)로 접근 가능한 컴퓨터에서 명령어를 실행할 수도 있다.

### kafka-topics.sh
이 커맨드 라인 툴을 통해 토픽(topic)과 관련된 명령을 실행할 수 있따.
토픽이란 카프카에서 데이터를 구분하는 가장 기본적인 개념이다.
마치 RDBMS(relational database management system)에서 사용하는 테이블과 유사하다고 볼 수 있다.
카프카 클러스터에 토픽은 여러 개 존재할 수 있다.
토픽에는 파티션(partition)이 존재하는데 파티션의 개수는 최소 1개부터 시작한다.
파티션은 카프카에서 토픽을 구성하는 데에 아주 중요한 요소이다.
파티션을 통해 한 번에 처리할 수 있는 데이터양을 늘릴 수 있고 토픽 내부에서도 파티션을 통해 데이터의 종류를 나누어 처리할 수 있기 때문이다.

**토픽 생성**
kafka-topics.sh를 통해 토픽 관련 명령을 실행할 수 있다.
<pre><code>bin/kafka-topics.sh \
 --create \
 --bootstrap-server my-kafka:9092 \
 --topic hellokafka</code></pre>

- --create 옵션으로 토픽을 생성하는 명령어임을 명시
- --bootstrap-server에는 토픽을 생성할 카프카 클러스터를 구성하는 브로커들의 IP와 port를 적는다.
- --topic에서 토픽 이름을 작성한다.  

클러스터 정보와 토픽 이름은 토픽을 만ㄷ르기 위한 필수 값이다.
<pre><code>bin/kafka-topics.sh \
 --create \
 --bootstrap-server my-kafka:9092 \
 --partitions 3 \
 --replication-factor 1 \
 --config retention.ms=172800000 \
 --topic hellokafka2</code></pre>
- --partitions는 파티션 개수를 지정할 수 있다.
- --replication-factor에는 토픽의 파티션을 복제할 복제 개수를 적는다.
- --config를 통해 kafka-topics.sh 명령에 포함되지 않은 추가적인 설정을 할 수 있다.

카프카 2.2 버전 이후로는 주키퍼와 통신하는 대신 카프카를 통해 토픽과 관련된 명령을 실행할 수 있게 되었다.

**토픽 리스트 조회**
<pre><code>bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --list
</code></pre>
카프카에 내부 관리를 위한 인터널 토픽이 존재하는데, 실질적으로 운영하는 데에 사용되지 않으므로 조회시 목록에서 제거할 수 있다.

**토픽 상세 조회**
<pre><code>bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --describe --topic hellokafka2
</code></pre>
이미 생성된 토픽의 상태를 --describe 옵션을 사용하여 확인할 수 있다.
파티션 개수가 몇 개인지, 복제된 파티션이 위치한 브로커 번호, 기타 토픽을 구성하는 설정들을 출력한다. 
토픽이 가진 파티션의 리더가 현재 어느 브로커에 존재하는지도 같이 확인할 수 있다.

카프카 클러스터의 성능이 생각보다 좋지 않다면 토픽 상세 조회 명령을 통해 토픽의 리더 파티션 쏠림 현상을 확인하는 것도 좋은 방법이다.

**토픽 옵션 수정**  
토픽에 설정된 옵션을 변경하기 위해서는 kafka-topics.sh 또는 kafka-configs.sh 두 개를 사용해야 한다.
파티션 개수 변경을 하려면 kafka-topics.sh를 사용해야 하고 토픽 삭제 정책인 리텐션 기간을 변경하려면 kafka-configs.sh를 사용해야 한다.
토픽 설정 옵션이 파편화된 이유는 토픽에 대한 정보를 관리하는 일부 로직이 다른 명령어로 넘어갔기 때문이다.

카프카 2.5까지는 kafka-topics.sh와 --alter 옵션을 사용하여 리텐션 기간을 변경할 수 있지만 추후 삭제될 예정이락 ㅗ경고 메시지가 발생하므로 kafka-configs.sh를 사용하자.

**파티션 개수 변경**
```bash
bin/kafka-topics.sh --bootstrap-server my-kafka:9092 \
--topic hello.kafka \
--alter \
--partitions 4
```

**리텐션 기간 변경**

```bash
bin/kafka-configs.sh --bootstrap-server my-kafka:9092 \
--entity-type topics \
--entity-name hello.kafka \
--alter --add-config retention.ms=86400000
```

**확인**

```bash
bin/kafka-configs.sh --bootstrap-server my-kafka:9092 \
--entity-type topics \
--entity-name hello.kafka \
--describe
```

### kafka-console-producer.sh
생성된 hellokafka 토픽에 데이터를 넣을 수 있는 kafka-console-producer.sh 명령어를 실행해보자.
토픽에 넣는 데이터는 '레코드(record)'라고 부르며 메시지 키(key)와 메시지 값(value)으로 이루어져 있다.
**키 없이 메시지 값만 보내기**
```bash
bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 \
 --topic hellokafka
```
키보드로 문자를 작성하고 엔터 키를 누르면 별다른 응답 없이 메시지 값이 전송된다.
주의할 점은 레코드 값은 UTF-8을 기반으로 Byte로 변환되고 ByteArraySerializer로만 직렬화된다는 점이다.

```bash
bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 \
--topic hello.kafka \
--property "parse.key=true" \
--property "key.separator=:"
```
- parse.key를 true로 두면 레코드를 전송할 때 메시지 키를 추가할 수 있다.
- 메시지 키와 메시지 값을 구분하는 구분자를 선언한다. key.separator를 선언하지 않으면 기본 설정은 Tab delimiter이다.
만약 key.seperator로 사용하는 구분자를 넣지 않고 엔터를 누르면 KafkaException과 함께 종료된다.

메시지 키와 메시지 값을 함께 전송한 레코드는 토픽의 파티션에 저장된다. 
메시지 키가 null인 경우에는 프로듀서가 파티션으로 전송할 때 레코드 배치 단위(레코드 전송 묶음)로 라운드로빈으로 정송한다.
메시지 키가 존재하는 경우에는 키의 해시값을 작성하여 존재하는 파티션 중 한 개에 할당된다.
이로 인해 메시지 키가 동일한 경우에는 동일한 파티션으로 전송된다.

이런 메시지 키와 파티션 할당은 프로듀서에서 설정된 파티셔너에 의해 결정되는데, 기본 파티셔너의 경우 이와 같은 동작을 보장한다.

### kafka-console-consumer.sh
hellokafka 토픽으로 전송한 데이터는 kafka-console-consumer.sh 명령어로 확인할 수 있다.
이때 필수 옵션으로 카프카 클러스터 정보, 토픽 이름이 필요하다.  
--from-beginning 옵션을 주면 토픽에 저장된 가장 처음 데이터부터 출력한다.
```bash
bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 \
--topic hello.kafka \
--from-beginning
```

데이터의 메시지 키와 메시지 값을 확인하고 싶다면 --property 옵션을 사용하면 된다.
```bash
bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 \
--topic hello.kafka \
--property print.key=true \
--property key.separator="-" \
--group hello-group \
--from-beginning
```
- 메시지 키를 확인하기 위해 print.key를 true로 설정
- 메시지 키 값을 구분하기 위해 key.separator를 설정했다.
- --group 옵션을 통해 신규 컨슈머 그룹(consumer group)을 생성했다. 컨슈머 그룹은 1개 이상의 컨슈머로 이루어져 있다.
컨슈머 그룹을 통해 가져간 토픽의 메시지는 가져간 메시지에 대해 커밋(commit)한다. 
커밋이란 컨슈머가 특정 레코드까지 처리를 완료했다고 레코드의 오프셋 번호를 카프카 브로커에 저장하는 것이다.

응답을 보면 전송했던 데이터 순서와 출력되는 순서가 다르다.
이는 카프카의 핵심인 파티션 개념 때문에 생기는 현상이다.
만약 토픽에 넣은 순서를 보장하고 싶다면 가장 좋은 방법은 파티션 1개로 구성된 토픽을 만드는 것이다.

### kafak-consumer-groups.sh
--list는 그룹의 리스트를 확인하는 옵션
```bash
bin/kafka-consumer-groups.sh --bootstrap-server my-kafka:9092 --list
```
```bash
bin/kafka-consumer-groups.sh --bootstrap-server my-kafka:9092 \
--group hello-group \
--describe
```
- GROUP: 어떤 컨슈머 그룹에 대한 상세 내용을 볼 것인지 --group 옵션을 통해 지정해야 한다.
- TOPIC: --describe옵션을 통해 컨슈머 그룹의 상세 내용을 확인할 수 있다.
- PARTITION: 조회한 컨슈머 그룹이 마지막으로 커밋한 토픽과 파티션을 나타낸다.
- CURRENT-OFFSET: 컨슈머 그룹이 가져간 토픽의 파티션에 가장 최신 오프셋이 몇 번인지 나타낸다.
- LOG-END-OFFSET: 해당 컨슈머 그룹의 컨슈머가 어느 오프셋까지 커밋했는지 알 수 있다.
- LAG: 컨슈머 그룹이 토픽의 파티션에 있는 데이터를 가져가는 데에 얼마나 지연이 발생했는지 나타내는 지표다.
- CONSUMER-ID: 컨슈머의 토픽(파티션) 할당을 카프카 내부적으로 구분하기 위해 사용하는 id이다.
- HOST: 컨슈머가 동작하는 host명을 출력한다.
- CLIENT-ID: 컨슈머에 할당된 id이다.

### kafka-verifiable-producer, consumer.sh
**간단한 네트워크 통신 테스트**
```bash
bin/kafka-verifiable-producer.sh --bootstrap-server my-kafka:9092 \
--max-messages 10 \
--topic verify-test
```
- --max-messages는 kafka-verifiable-producer.sh로 보내는 데이터 개수를 지정한다. 
만약 -1을 옵션값으로 입력하면 kafka-verifiable-producer.sh가 종료될 때까지 계속 데이터를 토픽으로 보낸다.
- 데이터를 받을 대상 토픽을 입력한다.
- 최초 실행 시점이 startup_complete와 함께 출력된다.
- 메시지별로 보낸 시간과 메시지 키, 값, 토픽, 저장된 파티션, 저장된 오프셋 번호가 출력된다.
- 10개 데이터가 모두 전송된 이후 통계값이 출력된다.

전송한 데이터는 kafka-verifiable-consumer.sh로 확인할 수 있다.
```bash
bin/kafka-verifiable-consumer.sh --bootstrap-server my-kafka:9092 \
--topic verify-test \
--group-id test-group
```
- 데이터를 가져오고자 하는 토픽인 verify-test를 --topic 옵션값으로 입력한다.
- --group-id 옵션으로 컨슈머 그룹을 지정한다.
- 컨슈머가 실행되면 startup_complete 문자여로가 시작 시간이 timestamp와 함께 출력된다.
- 컨슈머는 한 번에 다수의 메시지를 가져와서 처리하므로 한 번에 10개의 메시지를 정상적으로 받았음을 알 수 있다.

### kafka-delete-records.sh
0번부터 30 오프셋까지의 데이터를 지우기
```bash
vi delete-topic.json
```
```json
{"partitions": [{"topic": "test", "partition": 0, "offset":50}], "version":1 }
```
```bash
bin/kafka-delete-records.sh --bootstrap-server my-kafka:9092 \
--offset-json-file delete-topic.json
```