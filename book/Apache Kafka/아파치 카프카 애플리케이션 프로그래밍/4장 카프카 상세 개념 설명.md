## 토픽과 파티션
데이터의 생명주기 한가운데에 토픽이 있다.

### 적정 파티션 개수
토픽의 파티션 개수는 카프카의 성능과 관련이 있다.
그렇기 떄문에 토픽을 운영함에 있어 적절한 파티션 개수를 설정하고 운영하는 것이 매우 중요하다.

**토픽 생성 시 파티션 개수 고려사항**
- 데이터 처리량
- 메시지 키 사용 여부
- 브로커, 컨슈머 영향도

파티션은 카프카 병렬처리의 핵심이다.
파티션의 개수가 많아지면 많아질수록 1:1 매핑되는 컨슈머 개수가 늘어나기 때문이다.
그렇기 때문에 파티션 개수를 정할 때는 해당 토픽에 필요한 데이터 처리량을 측정하여 정하는 것이 중요하다.

데이터 처리 속도를 올리는 방법은 2가지다. 
- 컨슈머의 처리량을 늘리기
  - 서버 사양 스케일 업
  - GC 튜닝
  - 컨슈머 특성상 다른 시스템들과 연동되기 때문에 일정 수준 이상 처리량을 올리는 것은 매우 어렵다.
- 컨슈머를 추가해서 병렬처리량을 늘리기
  - 파티션 개수를 늘리고 파티션 개수만큼 컨슈머를 추가하는 방법은 데이터 처리량을 늘리는 확실한 방법이다.

**컨슈머 데이터 처리량과 프로듀서의 데이터 생성량, 파티션 개수 공식**
```
프로듀서 전송 데이터량 < 컨슈머 데이터 처리량 * 파티션 개수
```
파티션 개수만큼 컨슈머 스레드를 운영한다면 해당 토픽의 병렬 처리를 극대화할 수 있다.
만약 전체 컨슈머 데이터 처리량이 프로듀서가 보내는 데이터보다 적다면 컨슈머 랙이 생기고, 데이터 처리 지연이 방생하게 된다.
그렇기 때문에 컨슈머 전체 데이터 처리량이 프로듀서 데이터 처리량보다 많아야 한다.

만약 데이터 지연이 절대로 발생하면 안 된다면 프로듀서가 보내는 데이터의 최대치를 데이터 생성량으로 잡고 계산하면 된다.

파티션 개수를 무조건 늘리는 것만이 능사가 아니다. 파티션 개수를 늘리면 컨슈머, 브로커의 부담이 있기 떄문이다.

다음으로 메시지 키 사용 여부를 정한다.
메시지 키 사용 여부는 데이터 처리 순서와 밀접한 연관이 있다.

메시지 키를 사용하고 컨슈머에서 메시지 처리 순서가 보장되어야 한다면 최대한 파티션의 변화가 발생하지 않는 방향으로 운영해야 한다.
만약에 파티션 개수가 변해야 하는 경우에는 기존에 사용하던 메시지 키의 매칭을 그대로 가져가기 위해 커스텀 파티셔너를 개발하고 적용해야 한다.

마지막으로 고려해야 할 점은 브로커와 컨슈머의 영향도이다.
카프카에서 파티션은 각 브로커의 파일 시스템을 사용하기 때문에 파티션이 늘어나는 만큼 브로커에서 접근하는 파일 개수가 많아진다.

그런데 OS에서는 프로세스당 열 수 있는 파일 최대 갯수를 제한하고 있다.
그러므로 카프카 브로커가 접근하는 파일 개수를 안정적으로 유지하기 위해서는 각 브로커당 파티션 개수를 모니터링해야 한다.

### 토픽 정리 정책(cleanup.policy)
토픽의 데이터는 시간 또는 용량에 따라 삭제 규칙을 적용할 수 있다.

데이터를 더는 사용하지 않을 경우에는 cleanup.policy 옵션을 사용하여 데이터를 삭제할 수 있는데, cleanup.policy 옵션은 2가지 삭제 정책을 제공한다.
첫 번째는 delete(삭제)로 데아터의 완전 삭제이고, 두 번째는 compact(압축)로 동일 메시지 키의 가장 오래된 데이터를 삭제하는 것이다.

**토픽 삭제 정책(delete policy)**  
일반적으로 delete로 설정한다.
토픽의 데이터를 삭제할 때는 세그먼트 단위로 삭제를 진행한다.
세그먼트는 토픽의 데이터를 저장하는 명시적인 파일 시스템 단위이다.

세그먼트는 파티션마다 별개로 생성되며 세그먼트의 파일 이름은 오프셋 중 가장 작은 값이 된다.
세그먼트는 여러 조각으로 나뉘는데 segment.bytes 옵션으로 1개의 세그먼트 크기를 설정할 수 있다.
segment.bytes 크기보다 커질 경우에는 기존에 적재하던 세그먼트 파일을 닫고 새로운 세그먼트를 열어서 데이터를 저장한다.
데이터를 저장하기 위해 사용 중인 세그먼트를 액티브 세그먼트라고 한다.

삭제 정책이 실행되는 시점은 시간 또는 용량이 기준이 된다.
세그먼트 파일의 마지막 수정 시간이 retention.ms를 넘어가면 세그먼트는 삭제된다.
크기가 retention.bytes를 넘어간 세그먼트 파일들은 삭제된다.

**토픽 압축 정책(compact policy)**  
토픽의 압축은 일반적인 zip이나 tar 압축과는 다른 개념이다.
여기서 압축이란 메시지 키별로 해당 메시지 키의 레코드 중 오래된 데이터를 삭제하는 정책을 뜻한다.

메시지 키를 기준으로 오래된 데이터를 삭제하기 때문에 삭제 정책과 다르게 1개 파티션에서 오프셋의 증가가 일정하지 않을 수 있다.
1부터 10까지 오프셋이 있고, 4,5,6이 동일한 메시지 키를 가질 경우, 오프셋과 관계없이 중간에 있는 4번, 5번 오프셋의 레코드가 삭제될 수 있다는 뜻이다.

토픽 압축 정책은 카프카 스트림즈의 KTable과 같이 메시지 키를 기반으로 데이터를 처리할 경우 유용하다.
데이터의 흐름이 아닌 가장 마지막으로 업데이트된 메시지 키의 데이터가 중요할 경우 가장 최신의 데이터를 제외한 나머지 데이터들을 삭제할 수 있기 떄문이다.

압축 정책은 액티브 세그먼트를 제외한 나머지 세그먼트들에 한해서만 데이터를 처리한다.
min.cleanable.dirty.ratio 옵션값은 액티브 세그먼트를 제외한 세그먼트에 남아 있는 데이터의 테일(tail) 영역의 레코드 개수와 헤드(head) 영역의 레코드 개수의 비율을 뜻한다.
테일 영역의 레코드들은 '클린 로그'라고 부르고 압축이 완료됐기 떄ㅜㅁㄴ에 테일 영역에는 중복된 메시지 키가 없다.

'더티 비율(dirty ratio)'는 더티 영역의 메시지 개수를 압축 대상 세그먼트에 남아있는 데이터의 총 레코드 수(더티 영역 메시지 개수 + 클린 영역 메시지 개수)로 나눈 비율을 뜻한다.

더티비율을 올리면 한번 압축시 많은 데이터가 줄어들므로 압축 효과가 좋지만,
0.9 비율이 될 떄까지 용량을 차지하므로 용량 효율이 좋지 않다.

### ISR(In-Sync-Replicas)
ISR은 리더 파티션과 팔로워 파티션이 모두 싱크가 된 상태를 뜻한다.
ISR이라는 용어가 나온 이유는 팔로워 파티션이 리더 파티션으로부터 데이터를 복제하는 데에 시간이 걸리기 떄문이다.
프로듀서가 특정 파티션에 데이터를 저장하는 작업은 리더 파티션을 통해 처리한다.
리더 파티션에 새로운 레코드가 추가되어 오프셋이 증가하면 팔로워 파티션이 위치한 브로커는 리더 파티션의 데이터를 복제한다.

차이를 모니터링하기 위해 리더 파티션은 replica.lag.time.max.ms 값만큼의 주기를 가지고 팔로워 파티션이 데이터를 복제하는지 확인한다.
만약 팔로워 파티션이 replica.lag.time.max.ms값보다 더 긴 시간 동안 데이터를 가져가지 않는다면 해당 팔로워 파티션에 문제가 생긴 것으로 판단하고 ISP 그룹에서 제외한다.

ISP로 묶인 리더 파티션과 팔로워 파티션은 파티션에 존재하는 데이터가 모두 동일하기 떄문에 팔로워 파티션은 리더 파티션으로 새로 선출될 자격을 가진다.

일부 데이터 유실이 발생하더라도 중단 없이 지속적으로 토픽을 사용하고 싶다면 ISR이 아닌 팔로워 파티션을 리더로 선출하도록 설정할 수 있다.  
-> unclean.leader.election.enable  

false로 설정할 경우 리더 파티션이 존재하는 브로커가 다시 시작되기까지 기다린다.

일부 데이터가 유실되더라도 토픽과 연동 중인 서비스의 무중단 운영이 더 중요하다면 true로 설정하면 되고,
데이터가 유실되면 안 되는 경우에는 false로 설정해야 한다. 다만, 중단이 발생할 수 있다.
```shell
bin/kafka-toics.sh --bootstrap-server my-kafka:9092 \
--create --topic my-topic \
--config unclean.leader.election.enable=false
```

## 카프카 프로듀서
### acks 옵션
카프카 프로듀서의 acks 옵션은 0, 1, all 값을 가질 수 있다.
이 옵션을 통해 프로듀서가 전송한 데이터가 얼마나 신뢰성 높게 저장할지 지정할 수 있다.

**acks=0**  
프로듀서->리더 파티션 데이터 전송 시 데이터가 저장되었는지 확인하지 않는다는 뜻.
고로 전송이 실패한지도 알 수 없다.
그만큼 속도는 빠르다.

**acks=1**  
리더 파티션에만 정상적으로 적재되었는지 확인. -> 팔로워 파티션은 체크하지 않음

**acks=all or acks=-1**  
리더 파티션과 팔로워 파티션(ISR에 포함된 파티션)에 모두 정상적으로 적재되었는지 확인

acks를 all로 설정한 경우에는 토픽 단위로 설정 가능한 min.insync.replicas 옵션값에 따라 데이터의 안정성이 달라진다.
이 값이 1이면 acks=1과 동일한 동작 <- ISR 중 가정 처음 적재가 완료되는 파티션은 리더 파티션이기 때문.

min.insync.replicas를 설정할 때는 복제 개수도 함께 고려해야 한다.
브로커 중 한대가 고장나는 경우에 토픽에 데이터를 전송할 수 없기 때문이다.
그러므로 토픽별 min.insync.replicas 옵션값은 브로커 개수 미만으로 설정해서 운영해야 한다.

### 멱등성(idempotence) 프로듀서 
멱등성이란 여러 번 연산을 수행하더라도 동일한 결과를 나타내는 것.

멱등성 프로듀서: 동일 데이터를 여러 번 전송하더라도 카프카 클러스터에 단 한 번만 저장

0.11.0 이후 버전부터는 enable.idempotence 옵션을 사용하여 정확히 한번 전달을 지원한다.

멱등성 프로듀서는  기본 프로듀서와 달리 데이터를 브로커로 전달할 때 프로듀서 PID와 시퀀스 넘버를 함께 전달한다. 
브로커는 프로듀서의 PID와 시퀀스 넘버를 확인하여 동일한 메시지가 오는지 식별.

장애가 발생시 PID가 바뀌므로 멱등성 보장 X

시퀀스 넘버가 일정하지 않은 경우 OutOfOrderSequenceException이 발생할 수 있다.
순서가 중요ㅕ한 데이터를 전송하는 프로듀서는 해당 Exception이 발생했을 경우 대응하는 방안을 고려해야 한다.

### 트랜잭션(transaction) 프로듀서
트랜잭션 프로듀서는 다수의 파티션에 데이터를 저장할 경우 모든 데이터에 대해 동일한 원자성(atomic)을 만족시키기 위해 사용된다.

컨슈머는 기본적으로 프로듀서가 보내는 데이터가 파티션에 쌓이는 대로 모두 가져가서 처리한다. 
그러나 트랜잭션으로 묶인 데이터를 브로커에서 가져갈 때는 다르게 동작하도록 설정할 수 있다.

트랜잭션은 파티션의 레코드로 구분한다.

## 카프카 컨슈머
### 멀티 스레드 컨슈머
파티션을 여러 개로 운영하는 경우 데이터를 병렬 처리하기 위해서 파티션 개수와 컨슈머 개수를 동일하게 맞추는 것이 가장 좋은 방법이다.

**카프카 컨슈머 멀티 워커 스레드 전략**  
ExecutorService와 CachedThreadPool을 사용해서 처리

스레드를 사용하면 한번 poll()을 통해 받은 데이터를 병렬 처리함으로써 속도의 이점을 확실히 얻을 수 있다.

**주의**
- 스레드를 사용하므로써 데이터 처리가 끝나지 않았음에도 불구하고 커밋을 하기 때문에 리밸런싱, 컨슈머 장애 시에 데이터 유실이 발생할 수 잇다.
- 레코드 처리의 역전 현상

**카프카 컨슈머 멀티 스레드 전략**  
하나의 파티션은 동일 컨슈머 중 최대 1개까지 할당된다.
하나의 컨슈머는 여러 파티션에 할당될 수 있다.

특징을 잘 살리려면 1개의 애플리케이션에 구독하고자 하는 토픽의 파티션 개수만큼 컨슈머 스레드 개수를 늘려서 운영하는 것이다.

KafkaConsumer 클래스는 스레드 세이프하지 않다. 이 때문에 스레드별로 KafkaConsumer 인스턴스를 별개로 만들어서 운영해야만 한다.

### 컨슈머 랙
컨슈머 랙(LAG)은 토픽의 최신 오프셋과 컨슈머 오프셋 간의 차이다.
프로듀서는 계속해서 새로운 데이터를 파티션에 저장하고 컨슈머는 자신이 처리할 수 있는 만큼 데이터를 가져간다.

컨슈머 랙은 컨슈머가 정상 동작하는지 여부를 확인할 수 있기 때문에 컨슈머 애플리케이션을 운영한다면 필수적으로 모니터링해야 하는 지표이다. 

컨슈머 랙은 컨슈머 그룹과 토픽, 파티션 별로 생성된다.

**카프카 명령어를 사용하여 컨슈머 랙 조회**  
kafka-consumer-groups.sh 명령어를 사용하면 컨슈머 랙을 포함한 특정 컨슈머 그룹의 상태를 확인할 수 있다.

**컨슈머 metrics() 메서드를 사용하여 컨슈머 랙 조회**  
컨슈머 애플리케이션에서 KafkaConsumer 인스턴스의 metrics() 메서드를 활용하면 컨슈머 랙 지표를 확인할 수 있다.

**문제점**
- 컨슈머가 정상 동작할 경우에만 확인 가능
- 모든 컨슈머 애플리케이션에 컨슈머 랙 모니터링 코드를 중복해서 작성해야 함
- 컨슈머 랙을 모니터링하는 코드를 추가할 수 없는 카프카 서드 파티 애플리케이션의 컨슈머 랙 모니터링이 불가

**외부 모니터링 툴을 사용하여 컨슈머 랙 조회**  
#### 카프카 버로우
링크드인에서 공개한 오픈소스 컨슈머 랙 체크 툴

버로우에선 임계치가 아닌 슬라이딩 윈도우 계산을 통해 문제가 생긴 파티션과 컨슈머의 상태를 표현한다.

**컨슈머 랙 모니터링 아키텍처**
준비물
- 버로우: REST API를 통해 컨슈머 랙을 조회할 수 있다.
- 텔레그래프: 데이터 수집 및 전달에 특화된 툴. 버로우를 조회하여 데이터를 엘라스틱 서치에 전달한다.
- 엘라스틱 서치: 컨슈머 랙 정보를 담는 저장소
- 그라파나

### 컨슈머 배포 프로세스
**중단 배포**  
한정된 서버 자원을 운영하는 기업에 적합.

**무중단 배포**  
유연한 가상 서버를 사용하는 경우에 유용
 
## 스프링 카프카
### 스프링 카프카 프로듀서
스프링 카프카 프로듀서는 '카프카 템플릿(Kafka Template)'이라고 불리는 클래스를 사용하여 데이터를 전송할 수 있다.
카프카 템플릿은 프로듀서 팩토리 클래스를 통해 생성할 수 있다.

**기본 카프카 템플릿**  
yaml파일에 프로듀서 옵션(spring.kafka.producer.*)을 넣고 사용할 수 있다.

**커스텀 카프카 템플릿**  
프로듀서 팩토리를 통해 만든 카프카 템플릿 객체를 빈으로 등록하여 사용

### 스프링 카프카 컨슈머
스프링 카프카의 컨슈머는 기존 컨슈머를 2개의 타입으로 나누고 커밋을 7가지로 나누어 세분화했다.

- 레코드 리스너(MessageListener): 단 1개의 레코드를 처리
  - 파생된 형태로 AcknowledgingMessageListener, ConsumerAwareMessageListener, AcknowledgingConsumerAwareMEssageListener 등이 있다. 
- 배치 리스너(BatchMEssageListener): 한 번에 여러 개 레코드를 처리

카프카 컨슈머에서 커밋을 직접 구현할 때는 오토 커밋, 동기 커밋, 비동기 커밋 세 가지로 나뉘지만 실제 운영환경에서는 다양한 종류의 커밋을 구현해서 사용해야 한다.

스프링 카프카에서는 사용자가 사용할만한 커밋의 종류를 7가지
(RECORD, BATCH, TIME, COUNT, COUNT_TIME, MANUAL, MANUAL_IMMEDIATE)로 세분화하고 미리 로직을 만들어놓았다.

스프링 카프카에서는 커밋이라고 부르지 않고 'AckMode'라고 부른다. (기본값 BATCH)
- RECORD: 레코드 단위로 프로세싱 이후 커밋
- BATCH: poll 메서드로 호출된 레코드가 모두 처리된 이후 커밋
- TIME: 특정 시간 이후에 커밋
- COUNT: 특정 개수만큼 레코드가 처리된 이후에 커밋
- COUNT_TIME: TIME, COUNT 옵션 중 맞는 조건이 하나라도 나올 경우 커밋
- MANUAL: Acknowledgement.acknowledge() 메서드가 호출되면 다음번 poll()때 컴시을 한다.
- MANUAL_IMMEDIATE: Acknowledgement.acknowledge() 메서드가 호출되면즉시 커밋

리스너를 생성하고 사용하는 방식에는 크게 두 가지가 있다.
1. 기본 리스너 컨테이너 사용
2. 컨테이너 팩토리를 사용하여 직접 리스너를 만듦

**기본 리스너 컨테이너**
spring.kafka.consumer.*로 설정

기존 카프카 클라이언트에서 사용되지 않는 옵션들이기 때문에 각 옵션 사용 방법과 옵션값을 적절히 정의하고 사용해야 한다.

리스너를 사용하기 위해서는 KafkaListener 어노테이션을 포함한 메서드를 선언해야 한다.
KafkaListener 어노테이션에 포함된 파라미터에 따라 메서드에 필요한 파라미터 종류가 달라진다.

**커스텀 리스너 컨테이너**
서로 다른 설정을 가진 2개 이상의 리스너를 구현하거나 리밸런스 리스너를 구현하기 위해서는 커스텀 리스너 컨테이너를 사용해야 한다.

## 정리
카프카 상세 개념을 통해 파이프라인을 최적화하고 한정된 리소스에서 최고의 성능을 내도록 설정할 수 있기 때문이다.